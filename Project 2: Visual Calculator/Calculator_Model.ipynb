{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Calculator_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6qqfug8o0Jb"
      },
      "source": [
        "\n",
        "# Contents of This Note Book\n",
        "* Importing Libraries and Data Set\n",
        "* Preprocessing\n",
        "* Model Creation & Training\n",
        "* Saving the Model and its Weights\n",
        "* Model Prediction / Recognition\n",
        "* TF Model to TF Lite Conversion\n",
        "* TF Lite Interpreter\n",
        "* TF Lite Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okHx_cudS8kG"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME2bHLmWpYs3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0jBzzljTMzk"
      },
      "source": [
        "**Importing Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdSmZnVtlgAU"
      },
      "source": [
        "# load the drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# this will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# after executing the cell above, drive files will be present in\n",
        "# \"/content/drive/My Drive\"\n",
        "\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/dataset_new\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6f4RBnTWXK"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7353WCsDqRBX"
      },
      "source": [
        "# normalization\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# preparing data set\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "                                    '/content/drive/MyDrive/dataset_new/training set',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "                                    '/content/drive/MyDrive/dataset_new/test set',\n",
        "                                            target_size = (128, 128),\n",
        "                                            color_mode = 'grayscale',\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Th3-eZGTloZ"
      },
      "source": [
        "**Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDo6FjU_oBjU"
      },
      "source": [
        "# initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# convolution to extract features from images\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 1), activation = 'relu'))\n",
        "\n",
        "# max pooling to get max / largest values in feature map\n",
        "# down sampling technique to get the most present features\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# more convolution and max pooling layers\n",
        "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Conv2D(256, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# flattening is converting the data into a 1-dimensional array\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units = 1024, activation = 'relu'))\n",
        "classifier.add(Dense(units = 14, activation = 'softmax'))\n",
        "\n",
        "# compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# show summary of the created model\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98TtkwjETng_"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUnwLOlH5RbE"
      },
      "source": [
        "# less epochs because we have large number of data set and data set\n",
        "# is closely related so the model will learn it faster\n",
        "classifier.fit(training_set,\n",
        "               steps_per_epoch = 490,\n",
        "               epochs = 2,\n",
        "               validation_data = test_set,\n",
        "               validation_steps = 19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6yTWk0pTsWm"
      },
      "source": [
        "**Saving Model & Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEAXNcJNBSt2"
      },
      "source": [
        "# saving model and weights which can be used later without training \n",
        "classifier.save(\"/content/cal_2e2.h5\")\n",
        "classifier.save_weights(\"/content/cal_weights_2e2.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0c53yOtOvwA"
      },
      "source": [
        "**Recognition / Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyUvt38R4Hpy"
      },
      "source": [
        "# test images are manually upload from the 'files' tab on the left side\n",
        "# classification models take much time to train, so we can train them one time \n",
        "#   and can load them for prediction\n",
        "# ***load the model first for recognition directly*** \n",
        "\n",
        "test_image = image.load_img('/content/ten1424.jpg', target_size = (128, 128), color_mode='grayscale')\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "tf_prediction = np.argmax(result)\n",
        "print ('TF prediction:', tf_prediction)\n",
        "\n",
        "# printing model size in mb\n",
        "print ('TF Size:', round(os.path.getsize('/content/cal_2e2.h5')/(1024*1024), 3) , 'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_c_FMlNq3c9"
      },
      "source": [
        "# TF Lite Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzQPEJWtrfbM"
      },
      "source": [
        "**TF Model to TF Lite Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdiTLOTg-bFv"
      },
      "source": [
        "# convert & optimize the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(classifier)\n",
        "converter.optimization = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaaQsKu0rjMZ"
      },
      "source": [
        "**TF Lite Model Saving & Size Check**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzQr-NOZ-6m_"
      },
      "source": [
        "# save the model\n",
        "open('tflite_model.tflite', 'wb').write(tflite_model)\n",
        "\n",
        "# model size check\n",
        "print ('TF Lite Size:', round(os.path.getsize('tflite_model.tflite')/(1024), 3) , 'KB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHpWPETGr-XE"
      },
      "source": [
        "**Interpreter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mxNbknh_Crv"
      },
      "source": [
        "# 'interpreter' to interpret tf lite model and to get input & output details\n",
        "# models obtained from 'TfLiteConverter' can be run in python with 'interpreter'\n",
        "interpreter = tf.lite.Interpreter('tflite_model.tflite')\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# print input & output values & shapes to check everything is same \n",
        "# as the orignal tf model.\n",
        "# data types etc are changed during tf lite conversion & optimizations\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOC9vPUSsMRA"
      },
      "source": [
        "**Prediction from TF Lite Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mFQhzorABmS"
      },
      "source": [
        "testx = image.load_img('/content/three1154.jpg', target_size = (128, 128), color_mode='grayscale')\n",
        "testx = image.img_to_array(testx)\n",
        "testx = np.expand_dims(testx, axis = 0)\n",
        "\n",
        "# needed before execution\n",
        "# tensorFlow lite pre-plans tensor allocations to optimize inference,\n",
        "# so the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(input_details[0]['index'], testx)\n",
        "interpreter.invoke()\n",
        "\n",
        "# predicting from tf lite model\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# getting max index \n",
        "tf_lite_prediction = np.argmax(tflite_model_predictions)\n",
        "print ('TF Lite Prediction : ',tf_lite_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
